{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import requests\n",
    "import csv\n",
    "import os\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "from parsel import Selector\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_job_position_data_web(position: str) -> str:\n",
    "    \"\"\"Retorna uma string com o html da página\n",
    "\n",
    "    Args:\n",
    "        position (str): nome da vaga a ser buscada\n",
    "\n",
    "    Returns:\n",
    "        str: html com página com a lista de vagas encontradas\n",
    "    \"\"\"\n",
    "\n",
    "    opts = Options()\n",
    "\n",
    "    # uma sessão do navegador é criada quando instanciamos a classe 'Driver'. Em alguns casos seria necessario incluir\n",
    "    # o caminho para o driver do navegador como parâmetro, mas como incluímos esse arquivo dentro em um dos diretórios\n",
    "    # da variável $PATH (/usr/local/bin) isso não será necessário.\n",
    "    driver = webdriver.Firefox(options=opts)\n",
    "\n",
    "    # acessa a pagina dada pela URL\n",
    "    driver.get('https://www.vagas.com.br')\n",
    "\n",
    "    driver.implicitly_wait(5)\n",
    "\n",
    "    # o método '.find_element()' localiza os elementos da página atual da sessão, baseado no tipo de elemento/ID que o\n",
    "    # objeto possui e pelo nome da classe dado ao elemento do HTML. Após selecionarmos esse objeto, podemos passar\n",
    "    # uma string usando o método '.send_keys()' que simula as teclas pressionadas no teclado.\n",
    "    search_bar = driver.find_element(by=By.ID, value='nova-home-search')\n",
    "    search_bar.send_keys(position + Keys.ENTER)\n",
    "\n",
    "\n",
    "    driver.implicitly_wait(10)\n",
    "\n",
    "    prev_height = -1\n",
    "\n",
    "    # laço para rolar até o final da página\n",
    "    while True:\n",
    "        \n",
    "        time.sleep(4)\n",
    "\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\") # rola até o final da página - (x-coord, y-coord)\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")  # retona a posição atual em pixels\n",
    "        \n",
    "        if new_height == prev_height:\n",
    "            break\n",
    "\n",
    "        prev_height = new_height\n",
    "\n",
    "        try:\n",
    "            # nessa pagina o \"botão\" 'maisVagas' não foi configurado usando o elemento <button> do html mas sim um anchor\n",
    "            # element <a>, o qual possui uma ação configurada via javascript. Para executar a ação atribuída a esse elemento\n",
    "            # usamos o método '.execute_script()' e passamos como argumentos uma string contendo com script para executar a ação\n",
    "            # e um argumento que contém os dados da tag html.\n",
    "            see_more = driver.find_element(By.ID, 'maisVagas')\n",
    "            driver.execute_script('arguments[0].click()', see_more) # executa a ação que simula o clique de um botão\n",
    "            \n",
    "            time.sleep(3)\n",
    "\n",
    "        except:\n",
    "            time.sleep(1)\n",
    "\n",
    "    # html da página\n",
    "    page_source = driver.page_source\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    return page_source\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_job_opportunity_info(job_url: str, position: str) -> dict:\n",
    "    \"\"\"Retona um dicionário contendo as infomações da vaga.\n",
    "\n",
    "    Args:\n",
    "        job_url (str): url da vaga\n",
    "        position (str): nome da vaga buscada\n",
    "\n",
    "    Returns:\n",
    "        dict: dicionário com os atributos da vaga\n",
    "    \"\"\"\n",
    "\n",
    "    r = requests.get('https://www.vagas.com.br' + job_url)\n",
    "\n",
    "    job_page = BeautifulSoup(r.content, 'html')\n",
    "\n",
    "    \n",
    "    job_info = {}\n",
    "\n",
    "    job_info['site_da_vaga'] = 'Vagas.com'\n",
    "    job_info['posicao'] = position\n",
    "    job_info['link'] = 'https://www.vagas.com.br' + job_url\n",
    "\n",
    "    try:\n",
    "        job_info['data_publicação'] = job_page.select('.job-breadcrumb li')[0].text.strip()\n",
    "    except:\n",
    "        job_info['data_publicação'] = None\n",
    "\n",
    "    \n",
    "    job_info['data_coleta'] = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "    try:\n",
    "        job_info['titulo_da_vaga'] = job_page.select('.job-shortdescription__title')[0].text.strip()\n",
    "    except:\n",
    "        job_info['titulo_da_vaga'] = None\n",
    "\n",
    "\n",
    "    try:\n",
    "        job_info['local'] = job_page.select('.info-localizacao')[0].text.strip()\n",
    "    except:\n",
    "        job_info['local'] = None\n",
    "\n",
    "\n",
    "    try:\n",
    "        job_info['senioridade'] = job_page.select('.job-hierarchylist')[0].select_one('span').get('aria-label')\n",
    "    except:\n",
    "        job_info['senioridade'] = None\n",
    "\n",
    "\n",
    "    try:\n",
    "        job_info['modalidade'] = job_page.select('')[0].text.strip()\n",
    "    except:\n",
    "        job_info['modalidade'] = None\n",
    "\n",
    "    try:\n",
    "        job_info['contrato'] = job_page.select('')[0].text.strip()\n",
    "    except:\n",
    "        job_info['contrato'] = None\n",
    "\n",
    "\n",
    "    try:\n",
    "        job_info['beneficios'] = []\n",
    "        benefits = job_page.select('.job-benefits__list')[0].find_all('span')\n",
    "\n",
    "        for benefit in benefits:\n",
    "            job_info['beneficios'].append(benefit.text)\n",
    "\n",
    "    except:\n",
    "        job_info['beneficios'] = None\n",
    "    \n",
    "\n",
    "    \n",
    "    try:\n",
    "        job_info['regime'] = job_page.select('.info-modelo-contratual')[0].text.strip()\n",
    "    except:\n",
    "        job_info['regime'] = None\n",
    "\n",
    "    try:\n",
    "        job_info['contrato'] = job_page.select('')[0].text.strip()\n",
    "    except:\n",
    "        job_info['contrato'] = None\n",
    "\n",
    "    try:\n",
    "        job_info['codigo_vaga'] = job_page.select('.job-breadcrumb li')[1].text.strip()\n",
    "    except:\n",
    "        job_info['contrato'] = None\n",
    "\n",
    "\n",
    "    try:\n",
    "        job_info['descricao'] = job_page.select('.job-tab-content.job-description__text.texto')[0].text.strip()\n",
    "    except:\n",
    "        job_info['descricao'] = None\n",
    "        \n",
    "\n",
    "\n",
    "    return job_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_job_list_info(position: str, verbose: bool = True) -> list[dict]:\n",
    "    \"\"\"Retorna uma lista de dicionários com as vagas encontradas para a posição.\n",
    "\n",
    "    Args:\n",
    "        position (str): nome da vaga buscada\n",
    "        verbose (bool, optional): exibe progresso a cada 20 vagas adicionadas. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        list[dict]: lista de dicionários no padrão json com as informações das vagas\n",
    "    \"\"\"\n",
    "\n",
    "    page_source = get_job_position_data_web(position)\n",
    "\n",
    "    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "    job_opportunities = soup.select('.link-detalhes-vaga')\n",
    "\n",
    "    job_list = []\n",
    "\n",
    "    for index, job in enumerate(job_opportunities):\n",
    "        \n",
    "        if verbose == True and index % 20 == 0:\n",
    "            print(index)\n",
    "            \n",
    "        job_url = job['href']\n",
    "        job_info = get_job_opportunity_info(job_url, position)\n",
    "\n",
    "        job_list.append(job_info)\n",
    "\n",
    "    return job_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saving_data(position: str, job_list: list) -> None:\n",
    "    \"\"\"Salva os dados obtidos em arquivos JSON e excel\n",
    "\n",
    "    Args:\n",
    "        position (str): nome da posição\n",
    "        job_list (list): lista com as informações das vagas\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    position = position.replace(' ', '_').lower()\n",
    "\n",
    "    with open(f'../data/data_raw/data_json/{position}_vagas.json', 'w', encoding='utf8') as file:\n",
    "        json.dump(job_list, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "    df_position = pd.DataFrame(job_list)\n",
    "\n",
    "    df_position.to_excel(f'../data/data_raw/{position}_vagas.xlsx', index=False)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "120\n",
      "140\n",
      "160\n",
      "180\n",
      "200\n",
      "220\n",
      "240\n",
      "260\n",
      "280\n",
      "300\n",
      "320\n",
      "340\n"
     ]
    }
   ],
   "source": [
    "analista_vagas = get_job_list_info('Analista de Dados', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "cientista_vagas = get_job_list_info('Cientista de Dados', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "120\n",
      "140\n",
      "160\n",
      "180\n",
      "200\n",
      "220\n",
      "240\n",
      "260\n",
      "280\n"
     ]
    }
   ],
   "source": [
    "engenharia_vagas = get_job_list_info('Engenharia de Dados', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "saving_data('Analista de Dados', analista_vagas)\n",
    "saving_data('Cientista de Dados', cientista_vagas)\n",
    "saving_data('Engenharia de Dados', engenharia_vagas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "empresa_jr",
   "language": "python",
   "name": "empresa_jr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
